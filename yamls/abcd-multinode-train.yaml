apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: p4rodrig-cstest
spec:
  slotsPerWorker: 8
  runPolicy:
    cleanPodPolicy: Running
    backoffLimit: 0
  mpiReplicaSpecs:
    Launcher:
      restartPolicy: Never
      replicas: 1
      template:
         spec:
           restartPolicy: Never
           serviceAccountName: cswineford
           nodeSelector:
             brightcomputing.com/node-category: 'compute'
           volumes:
           - name: home
             persistentVolumeClaim:
               claimName: cswineford-home-pvc
           - name: scratch
             emptyDir: {}
           hostIPC: true
           containers:
           - image: vault.habana.ai/gaudi-docker/1.13.0/ubuntu20.04/habanalabs/pytorch-installer-2.1.0:latest
             name: mnjob-pytorch
             imagePullPolicy: Always
             resources:
               requests:
                 cpu: 2
                 memory: 4Gi
               limits:
                 cpu: 4
                 memory: 8Gi
             volumeMounts:
             - name: home
               mountPath: /home/cswineford
             - name: scratch
               mountPath: /scratch
             workingDir: /home/cswineford/multi-node
             command: ["/bin/bash", "-c"]
             args:
             - >-
               #echo 'put your commands here';
               #hl-smi;
               pwd > testoutput.txt;
               cd /home/cswineford/multi-node;
               ls >> testoutput.txt;

               outdir=/home/cswineford/outputs/$(date +'%Y-%m-%d:%H%M');
               mkdir $outdir;
               #chmod -R 777 /home/p4rodrig/outputs;

               declare -xir NUMBER_OF_NODES=2;  #match to replicas
               declare -xir NUMBER_OF_DEVICES_PER_HLS=8;
               declare -xir NUMBER_OF_DEVICES="$((NUMBER_OF_NODES * NUMBER_OF_DEVICES_PER_HLS))";

               #declare -xr HOME_DIR='/home/p4rodrig';
               sleep 15;
               export HOSTSFILE=${HOSTSFILE:-$OMPI_MCA_orte_default_hostfile};
               declare -xr MASTER_ADDR=$(head -n 1 $HOSTSFILE | sed -n s/[[:space:]]slots.*//p);
               declare -xr MASTER_PORT=${MASTER_PORT:-15566};
               #declare -xr MASTER_ADDR=$(mpirun --allow-run-as-root -n 1 hostname -i 2>/dev/null |tail -n 1);

               export PYTHONPATH=/usr/lib/habanalabs:/home/p4rodrig/.local_avacado_test/lib/python3.8/site-packages/:$PYTHONPATH;
               #export HOME=/home/p4rodrig;

               export OMP_NUM_THREADS=1;
               declare -xr MPI_ROOT=${MPI_ROOT:-/opt/amazon/openmpi/};

               #hl-smi;
               pwd > jobout.txt;
               echo $MASTER_ADDR >> jobout.txt;
               cd /home/cswineford/multi-node;
               pwd >> jobout.txt;   
            
               #export HABANA_LOGS=~/.habana_logs;
               #export ENABLE_CONSOLE=False;
               #False 
               #export LOG_LEVEL_ALL=4;

               sleep 15;
               pip3 install matplotlib;
               mpirun --allow-run-as-root  \
                      --prefix ${MPI_ROOT} \
                      -np 16 -bind-to core --map-by ppr:4:socket:PE=6 \
                      -rank-by core --report-bindings \
                      --tag-output \
                      --merge-stderr-to-stdout \
                      -x PYTHONPATH  \
                      -x MASTER_ADDR \
                      -x ENABLE_CONSOLE=False \
                      -x LOG_LEVEL_ALL=4 \
                      python3 ./train.py --train_data /home/cswineford/behavioral/SubjectData_Binary_Crop_RewNeuCue_SMOTEd.csv --batch_size 16 --epochs 600 --outdir $outdir >> $outdir/training0.log;
    Worker:
      replicas: 2
      template:
        spec:
          restartPolicy: Never
          serviceAccountName: cswineford
          volumes:
           - name: home
             persistentVolumeClaim:
               claimName: cswineford-home-pvc
           - name: scratch
             emptyDir: {}
          hostIPC: true
          containers:
          - image: vault.habana.ai/gaudi-docker/1.13.0/ubuntu20.04/habanalabs/pytorch-installer-2.1.0:latest
            name: mnjob-pytorch
            resources:
              limits:
                habana.ai/gaudi: 8
                cpu: 95
                memory: 409Gi
                hugepages-2Mi: 95000Mi
              requests:
                habana.ai/gaudi: 8
                cpu: 95
                memory: 409Gi
                hugepages-2Mi: 95000Mi
            volumeMounts:
             - name: home
               mountPath: /home/cswineford
             - name: scratch
               mountPath: /scratch
           
